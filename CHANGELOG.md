# Changelog - BA Trading System Verbesserungen

## [2025-11-16] - Data Leakage Fix & ML Improvements

### üîí Data Leakage Behebung

**Problem:** Doppelte Skalierung f√ºhrte zu Data Leakage
- Sklearn MLP hatte StandardScaler in Pipeline, w√§hrend bereits in ModelComparison.py skaliert wurde

**L√∂sung:**
- Entfernt StandardScaler aus `train_sklearn_nn()` Pipeline in `Models_Wrapper.py:141`
- Zentrale Skalierung erfolgt nur noch in `ModelComparison.py:69-87`
- Scaler wird **nur auf X_train gefittet**, dann auf beide Sets angewendet
- Klarstellende Kommentare hinzugef√ºgt

### ‚öôÔ∏è Zeitreihen-gerechte Hyperparameter-Optimierung

**Random Forest (`Models_Wrapper.py:257-339`):**
- GridSearchCV mit TimeSeriesSplit implementiert
- Parameter-Grid: n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features
- Nutzt `training.cross_validation.n_splits` aus Config (default: 5)
- Optional: `use_gridsearch` Flag zum Deaktivieren

**Sklearn MLP (`Models_Wrapper.py:125-225`):**
- GridSearchCV mit TimeSeriesSplit implementiert
- Parameter-Grid: hidden_layer_sizes, alpha, learning_rate_init
- Kleinerer Grid wegen l√§ngerer Trainingszeit
- Nutzt gleiche TimeSeriesSplit-Konfiguration

### üß† PyTorch-Modell Verbesserungen (`Models_Wrapper.py:50-190`)

**Neue Features:**
- **Validierungs-Split:** Chronologischer Split (letzten 20% des Trainingssets)
- **Early Stopping:** Stoppt nach 20 Epochen ohne Verbesserung
- **Seeds:** Reproduzierbarkeit durch `np.random.seed(42)`, `torch.manual_seed(42)`
- **Learning Rate Scheduler:** ReduceLROnPlateau (optional, default: True)
- **Bessere Ausgaben:** Zeigt Train Loss, Val Loss und LR w√§hrend Training

**Konfiguration:**
- `validation_split`: Anteil f√ºr Validierung (default: 0.2)
- `early_stopping_patience`: Geduld in Epochen (default: 20)
- `use_scheduler`: Learning Rate Scheduler (default: True)

### üõ°Ô∏è Robustheit & Qualit√§tssicherung

**time_series_split Validierung (`Dataprep.py:192-244`):**
- Pr√ºft minimale Trainingsset-Gr√∂√üe (min_train_size: 50)
- Pr√ºft minimale Testset-Gr√∂√üe (min_test_size: 10)
- Warnt bei sehr kleinen Datasets (< 100 Samples)
- Wirft aussagekr√§ftige Exceptions bei ung√ºltigen Splits

**Baseline-Modell (`Models_Wrapper.py:473-502`):**
- Naive Predictor: y_pred[t] = y[t-1]
- Dient als Vergleichsma√üstab
- Wird automatisch in ModelComparison trainiert
- ML-Modelle sollten Baseline √ºbertreffen

### üìà SDAX Index Integration

**Config (`config.yaml:12-15, 37-43`):**
- SDAX Index hinzugef√ºgt: `.SDAXI`
- Feature `change_sdax` zu input_features hinzugef√ºgt
- Dokumentation aktualisiert (Large Cap vs Small Cap)

**DataGrabber (`Datagrabber.py:84`):**
- L√§dt automatisch alle Indizes aus Config
- Kommentar aktualisiert: "DAX, SDAX, VDAX"

**Feature Engineering (`Dataprep.py:88-114`):**
- `change_sdax`: Prozentuale √Ñnderung des SDAX
- Analog zu `change_dax` implementiert
- Fallback auf 0.0 falls SDAX-Daten fehlen
- Sucht nach Spalten mit "SDAXI" oder "SDAX"

### üìä Verbesserungen im Modellvergleich

**ModelComparison.py:**
- Baseline-Modell wird als erstes trainiert
- Bessere Ausgabe mit Hinweis auf Baseline-Zweck
- Importiert `train_naive_baseline`

### ‚úÖ Zusammenfassung

**Was wurde behoben:**
- ‚úÖ Data Leakage beim Scaling vollst√§ndig eliminiert
- ‚úÖ Zeitreihen-gerechte CV f√ºr Random Forest und MLP
- ‚úÖ PyTorch robuster mit Early Stopping und Validation Split
- ‚úÖ Validierung der Split-Gr√∂√üen
- ‚úÖ Baseline-Modell f√ºr bessere Evaluation

**Was wurde hinzugef√ºgt:**
- ‚úÖ SDAX Index als zus√§tzliches Feature
- ‚úÖ change_sdax Feature f√ºr Small Cap Marktdynamik
- ‚úÖ Bessere Reproduzierbarkeit durch Seeds
- ‚úÖ Umfassende Dokumentation in Kommentaren

**Erwartete Verbesserungen:**
- üìà Bessere Modellg√ºte durch optimierte Hyperparameter
- üîç Validere Evaluation durch korrekte Skalierung
- üìä Mehr Marktinformationen durch SDAX
- üéØ Klarere Baseline zum Vergleich
